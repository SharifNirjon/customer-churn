{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOmIbI6eRjxyoLpDEMW1Y5R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SharifNirjon/customer-churn/blob/modeling_customer_churn/modeling_customer_churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02L1AZ36Va9w",
        "outputId": "0fe0f9cc-3443-45ce-ac83-d4e4abe22a88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, roc_auc_score, roc_curve, f1_score\n",
        ")\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "!pip install optuna\n",
        "import optuna\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import joblib\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_save_path='/content/processed_telco_churn.csv'\n",
        "df=pd.read_csv(df_save_path)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "fIWKCH-1Vi6u",
        "outputId": "0542dbea-0275-4795-f2fe-ffebfa08232c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   gender  SeniorCitizen Partner Dependents    tenure PhoneService  \\\n",
              "0  Female              0      No         No -0.307022           No   \n",
              "1  Female              0      No         No  3.861085          Yes   \n",
              "2    Male              0     Yes        Yes  0.526599          Yes   \n",
              "3  Female              0     Yes        Yes  3.861085          Yes   \n",
              "4  Female              0     Yes        Yes -0.376491           No   \n",
              "\n",
              "  PaperlessBilling  MonthlyCharges  TotalCharges  \\\n",
              "0               No       -2.807879     -0.330903   \n",
              "1              Yes       -5.321187     -0.309476   \n",
              "2              Yes       -1.271261     -0.291377   \n",
              "3              Yes       -0.100505     -0.121118   \n",
              "4              Yes       -4.783530     -0.343480   \n",
              "\n",
              "   MultipleLines_No phone service  ...  StreamingTV_Yes  \\\n",
              "0                            True  ...             True   \n",
              "1                           False  ...            False   \n",
              "2                           False  ...             True   \n",
              "3                           False  ...             True   \n",
              "4                            True  ...            False   \n",
              "\n",
              "   StreamingMovies_No internet service  StreamingMovies_Yes  \\\n",
              "0                                False                 True   \n",
              "1                                 True                False   \n",
              "2                                False                 True   \n",
              "3                                False                 True   \n",
              "4                                False                False   \n",
              "\n",
              "   Contract_One year  Contract_Two years  \\\n",
              "0               True               False   \n",
              "1              False                True   \n",
              "2               True               False   \n",
              "3               True               False   \n",
              "4              False               False   \n",
              "\n",
              "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
              "0                                  False                            True   \n",
              "1                                  False                           False   \n",
              "2                                  False                           False   \n",
              "3                                   True                           False   \n",
              "4                                  False                            True   \n",
              "\n",
              "   PaymentMethod_Mailed check  tenure_bucket  churn_label  \n",
              "0                       False              0            0  \n",
              "1                       False              4            0  \n",
              "2                        True              1            0  \n",
              "3                       False              4            0  \n",
              "4                       False              0            0  \n",
              "\n",
              "[5 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a875ed6-c6a7-47a2-bf16-df9d3a5f9181\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>MultipleLines_No phone service</th>\n",
              "      <th>...</th>\n",
              "      <th>StreamingTV_Yes</th>\n",
              "      <th>StreamingMovies_No internet service</th>\n",
              "      <th>StreamingMovies_Yes</th>\n",
              "      <th>Contract_One year</th>\n",
              "      <th>Contract_Two years</th>\n",
              "      <th>PaymentMethod_Credit card (automatic)</th>\n",
              "      <th>PaymentMethod_Electronic check</th>\n",
              "      <th>PaymentMethod_Mailed check</th>\n",
              "      <th>tenure_bucket</th>\n",
              "      <th>churn_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>-0.307022</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>-2.807879</td>\n",
              "      <td>-0.330903</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>3.861085</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>-5.321187</td>\n",
              "      <td>-0.309476</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.526599</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>-1.271261</td>\n",
              "      <td>-0.291377</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3.861085</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>-0.100505</td>\n",
              "      <td>-0.121118</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>-0.376491</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>-4.783530</td>\n",
              "      <td>-0.343480</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 32 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a875ed6-c6a7-47a2-bf16-df9d3a5f9181')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a875ed6-c6a7-47a2-bf16-df9d3a5f9181 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a875ed6-c6a7-47a2-bf16-df9d3a5f9181');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#target is churn_label\n",
        "X=df.drop(\"churn_label\", axis=1)\n",
        "y=df[\"churn_label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "O0tm5AogV1UY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_features_path=Path.cwd()/'models'/'model_features.pkl'\n",
        "model_features_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "joblib.dump(X_train.columns.tolist(), model_features_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8YxDD_9WKNK",
        "outputId": "2bba3d3e-3488-4a0a-a412-6006ba95505d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/models/model_features.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "initializing XGBoost\n"
      ],
      "metadata": {
        "id": "fAw-m-RpW_hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb = XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    n_estimators=300,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=0.1,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1,\n",
        "    device=\"cuda\",\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "7g9mMVKUWNqj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fl7D6yJW337i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad6e42e8",
        "outputId": "9c63f960-7998-4b07-d514-dc63732a3669"
      },
      "source": [
        "print(xgb.enable_categorical)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cf44rxVB5Pq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "pYF02uYhXGrb",
        "outputId": "0cf4e333-aed7-4893-e95c-cbf2a94c6b6b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:gender: object, Partner: object, Dependents: object, PhoneService: object, PaperlessBilling: object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/data.py\u001b[0m in \u001b[0;36mpandas_feature_info\u001b[0;34m(data, meta, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0mnew_feature_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pandas_dtype_mapper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'object'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3317810685.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m             \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEvalsLog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m             train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[0m\u001b[1;32m   1788\u001b[0m                 \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \"\"\"\n\u001b[1;32m    701\u001b[0m     \u001b[0;31m# Feature_types contains the optional reference categories from the booster object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m     train_dmatrix = create_dmatrix(\n\u001b[0m\u001b[1;32m    703\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36m_create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_can_use_qdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbooster\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"gblinear\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m                 return QuantileDMatrix(\n\u001b[0m\u001b[1;32m   1258\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_bin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_bin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, max_quantile_batches, data_split_mode)\u001b[0m\n\u001b[1;32m   1766\u001b[0m                 )\n\u001b[1;32m   1767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m         self._init(\n\u001b[0m\u001b[1;32m   1769\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m             \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data, ref, enable_categorical, max_quantile_blocks, **meta)\u001b[0m\n\u001b[1;32m   1830\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m         )\n\u001b[0;32m-> 1832\u001b[0;31m         \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1833\u001b[0m         \u001b[0;31m# delay check_call to throw intermediate exception first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m         \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m  \u001b[0;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, fn, dft_ret)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;31m# Defer the exception in order to return 0 and stop the iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temporary_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/data.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m   1630\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1632\u001b[0;31m         \u001b[0minput_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1633\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minput_data\u001b[0;34m(data, feature_names, feature_types, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m                 \u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temporary_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m                 new, feature_names, feature_types = _proxy_transform(\n\u001b[0m\u001b[1;32m    666\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m                     \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_proxy_transform\u001b[0;34m(data, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_pa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_pandas_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m         df, feature_names, feature_types = _transform_pandas_df(\n\u001b[0m\u001b[1;32m   1686\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_categorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_transform_pandas_df\u001b[0;34m(data, enable_categorical, feature_names, feature_types, meta)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0mfeature_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_categories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ref_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m     feature_names, feature_types = pandas_feature_info(\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/data.py\u001b[0m in \u001b[0;36mpandas_feature_info\u001b[0;34m(data, meta, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0mnew_feature_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pandas_dtype_mapper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0m_invalid_dataframe_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_types\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_invalid_dataframe_dtype\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"DataFrame.dtypes for data must be int, float, bool or category.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\"\"{type_err} {_ENABLE_CAT_ERR} {err}\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:gender: object, Partner: object, Dependents: object, PhoneService: object, PaperlessBilling: object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ============================================\n",
        "# FIX:  ENCODE ALL CATEGORICAL VARIABLES\n",
        "# ============================================\n",
        "print(\"=\"*80)\n",
        "print(\"üîß ENCODING CATEGORICAL VARIABLES FOR XGBOOST\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Check current data types\n",
        "print(\"\\nüìä Current Data Types:\")\n",
        "object_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "print(f\"   Object columns found: {len(object_cols)}\")\n",
        "for col in object_cols:\n",
        "    print(f\"   ‚Ä¢ {col}:  {X_train[col].unique()[:5]}\")\n",
        "\n",
        "# Binary categorical columns (Yes/No, Male/Female)\n",
        "binary_cols = ['gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']\n",
        "\n",
        "# Method 1: Map binary columns to 0/1\n",
        "print(\"\\nüîÑ Encoding binary columns...\")\n",
        "for col in binary_cols:\n",
        "    if col in X_train.columns:\n",
        "        unique_vals = X_train[col].unique()\n",
        "        print(f\"   {col}: {unique_vals}\")\n",
        "\n",
        "        if len(unique_vals) == 2:\n",
        "            # Binary encoding\n",
        "            if 'Yes' in unique_vals or 'No' in unique_vals:\n",
        "                X_train[col] = X_train[col].map({'No': 0, 'Yes':  1})\n",
        "                X_test[col] = X_test[col].map({'No': 0, 'Yes': 1})\n",
        "            elif 'Male' in unique_vals or 'Female' in unique_vals:\n",
        "                X_train[col] = X_train[col].map({'Female': 0, 'Male':  1})\n",
        "                X_test[col] = X_test[col].map({'Female': 0, 'Male': 1})\n",
        "\n",
        "            print(f\"   ‚úÖ {col} encoded to:  {X_train[col].unique()}\")\n",
        "\n",
        "# Verify all columns are now numeric\n",
        "print(\"\\n‚úÖ Verification:\")\n",
        "remaining_objects = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "if len(remaining_objects) == 0:\n",
        "    print(\"   All columns are now numeric!\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è Still have object columns: {remaining_objects}\")\n",
        "\n",
        "print(f\"\\nüìä Final Data Types:\")\n",
        "print(X_train.dtypes. value_counts())\n",
        "\n",
        "# Now train XGBoost\n",
        "print(\"\\nüöÄ Training XGBoost...\")\n",
        "xgb. fit(X_train, y_train)\n",
        "print(\"‚úÖ Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnHzbUNNXMWb",
        "outputId": "14dec015-dd97-44e0-b4b7-e8b8f0aae617"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üîß ENCODING CATEGORICAL VARIABLES FOR XGBOOST\n",
            "================================================================================\n",
            "\n",
            "üìä Current Data Types:\n",
            "   Object columns found: 5\n",
            "   ‚Ä¢ gender:  ['Male' 'Female']\n",
            "   ‚Ä¢ Partner:  ['Yes' 'No']\n",
            "   ‚Ä¢ Dependents:  ['Yes' 'No']\n",
            "   ‚Ä¢ PhoneService:  ['Yes' 'No']\n",
            "   ‚Ä¢ PaperlessBilling:  ['Yes' 'No']\n",
            "\n",
            "üîÑ Encoding binary columns...\n",
            "   gender: ['Male' 'Female']\n",
            "   ‚úÖ gender encoded to:  [1 0]\n",
            "   Partner: ['Yes' 'No']\n",
            "   ‚úÖ Partner encoded to:  [1 0]\n",
            "   Dependents: ['Yes' 'No']\n",
            "   ‚úÖ Dependents encoded to:  [1 0]\n",
            "   PhoneService: ['Yes' 'No']\n",
            "   ‚úÖ PhoneService encoded to:  [1 0]\n",
            "   PaperlessBilling: ['Yes' 'No']\n",
            "   ‚úÖ PaperlessBilling encoded to:  [1 0]\n",
            "\n",
            "‚úÖ Verification:\n",
            "   All columns are now numeric!\n",
            "\n",
            "üìä Final Data Types:\n",
            "bool       21\n",
            "int64       7\n",
            "float64     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üöÄ Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:08] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "UhEcS6cK4VQG",
        "outputId": "893be677-1e65-4a11-e4a8-b43675d22e91"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, device='cuda', early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric='logloss',\n",
              "              feature_types=None, feature_weights=None, gamma=0.1,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
              "              num_parallel_tree=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"‚ñ∏\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"‚ñæ\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, feature_weights=None, gamma=0.1,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
              "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, feature_weights=None, gamma=0.1,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
              "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=xgb.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVuH1j9p4ZLa",
        "outputId": "fb418184-4979-428d-92e2-3d62be0cc4ad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:774: UserWarning: [18:24:16] WARNING: /workspace/src/common/error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  return func(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba = xgb.predict_proba(X_test)[:, 1]"
      ],
      "metadata": {
        "id": "8PSHRYzf4mMU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    param={\n",
        "        'objective':'binary:logistic',\n",
        "        'eval_metric':'logloss',\n",
        "        'use_label_encoder':False,\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.5, 2),\n",
        "        'random_state': 42,\n",
        "        'use_label_encoder': False,\n",
        "        'device': \"cuda\"\n",
        "    }\n",
        "\n",
        "    model=XGBClassifier(**param)\n",
        "\n",
        "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    scores=cross_val_score(model, X_train, y_train, cv=cv, scoring='f1')\n",
        "    return scores.mean()\n",
        "\n",
        "study=optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"Best trial: \")\n",
        "trial=study.best_trial\n",
        "print(trial.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LItPrQHU4orH",
        "outputId": "4985a8b3-8ebb-4a71-85ca-d1f6384ed0da"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-01-15 18:24:23,990] A new study created in memory with name: no-name-b06e2d7f-ee93-4bab-9a6f-adb18f17f2b9\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:24] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:24] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:24] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:24,903] Trial 0 finished with value: 0.9717755813126644 and parameters: {'learning_rate': 0.12181767598524088, 'max_depth': 10, 'n_estimators': 213, 'subsample': 0.9642716364706151, 'colsample_bytree': 0.9509756094501741, 'gamma': 0.41367116325815745, 'reg_alpha': 0.8990605983443712, 'reg_lambda': 0.8516577322505404}. Best is trial 0 with value: 0.9717755813126644.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:24] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:25] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:25] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:26,147] Trial 1 finished with value: 0.9690595287545175 and parameters: {'learning_rate': 0.29094409344315164, 'max_depth': 7, 'n_estimators': 369, 'subsample': 0.5237032628604688, 'colsample_bytree': 0.5430689079942129, 'gamma': 2.242189060116554, 'reg_alpha': 0.9211503123425862, 'reg_lambda': 0.7442374607926866}. Best is trial 0 with value: 0.9717755813126644.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:26] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:26] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:26] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:26,915] Trial 2 finished with value: 0.9687418127708826 and parameters: {'learning_rate': 0.03672982383612063, 'max_depth': 3, 'n_estimators': 295, 'subsample': 0.8630518625566916, 'colsample_bytree': 0.8479098615367351, 'gamma': 2.6663042584425316, 'reg_alpha': 0.8025876885366189, 'reg_lambda': 0.7168942194570574}. Best is trial 0 with value: 0.9717755813126644.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:26] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:27] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:27] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:28,117] Trial 3 finished with value: 0.9739856137835355 and parameters: {'learning_rate': 0.07234276616237167, 'max_depth': 9, 'n_estimators': 308, 'subsample': 0.7992662453687625, 'colsample_bytree': 0.9962808123297824, 'gamma': 0.050942319020360616, 'reg_alpha': 0.9563216041983362, 'reg_lambda': 1.1099812926673023}. Best is trial 3 with value: 0.9739856137835355.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:28] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:28] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:28] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:28,657] Trial 4 finished with value: 0.9698358332796593 and parameters: {'learning_rate': 0.09648969242337854, 'max_depth': 10, 'n_estimators': 238, 'subsample': 0.7276261776511015, 'colsample_bytree': 0.7947267165775135, 'gamma': 2.5719228520912365, 'reg_alpha': 0.5723906416532604, 'reg_lambda': 1.2624660999262771}. Best is trial 3 with value: 0.9739856137835355.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:28] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:28] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:29] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:29,558] Trial 5 finished with value: 0.9668877444222262 and parameters: {'learning_rate': 0.011799361862858694, 'max_depth': 3, 'n_estimators': 347, 'subsample': 0.751177384266944, 'colsample_bytree': 0.8391411791401513, 'gamma': 2.8482105429971902, 'reg_alpha': 0.6636792317203535, 'reg_lambda': 1.7229759079879332}. Best is trial 3 with value: 0.9739856137835355.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:29] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:29] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:29] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:30,208] Trial 6 finished with value: 0.9702725568029577 and parameters: {'learning_rate': 0.20439971182770483, 'max_depth': 6, 'n_estimators': 358, 'subsample': 0.8194449085844961, 'colsample_bytree': 0.7555059929322396, 'gamma': 3.66698035485102, 'reg_alpha': 0.6234863545315095, 'reg_lambda': 1.8856526928129882}. Best is trial 3 with value: 0.9739856137835355.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:30,674] Trial 7 finished with value: 0.966473578000155 and parameters: {'learning_rate': 0.05172490582192039, 'max_depth': 7, 'n_estimators': 169, 'subsample': 0.8862947839784845, 'colsample_bytree': 0.5159431869949802, 'gamma': 2.3750252367237286, 'reg_alpha': 0.6134014021256577, 'reg_lambda': 1.7464394287907983}. Best is trial 3 with value: 0.9739856137835355.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:31,468] Trial 8 finished with value: 0.9727916041168932 and parameters: {'learning_rate': 0.0381521448523799, 'max_depth': 7, 'n_estimators': 195, 'subsample': 0.5365072693193834, 'colsample_bytree': 0.6414040363550753, 'gamma': 0.28898967383644114, 'reg_alpha': 0.04179885285423024, 'reg_lambda': 1.1346255079928396}. Best is trial 3 with value: 0.9739856137835355.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:32,140] Trial 9 finished with value: 0.97239049123653 and parameters: {'learning_rate': 0.05948691011645124, 'max_depth': 5, 'n_estimators': 280, 'subsample': 0.6066838724406657, 'colsample_bytree': 0.6424611544813121, 'gamma': 1.5311244723671247, 'reg_alpha': 0.57503228073152, 'reg_lambda': 0.959442451643802}. Best is trial 3 with value: 0.9739856137835355.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:32] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:32] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:32] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:33,165] Trial 10 finished with value: 0.9658769336696204 and parameters: {'learning_rate': 0.019730717829079633, 'max_depth': 9, 'n_estimators': 469, 'subsample': 0.6767835812620935, 'colsample_bytree': 0.9980468198957577, 'gamma': 4.780411748858894, 'reg_alpha': 0.28075254803401417, 'reg_lambda': 1.3931117913056157}. Best is trial 3 with value: 0.9739856137835355.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:33] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:33] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:33] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:33,683] Trial 11 finished with value: 0.9710386865847586 and parameters: {'learning_rate': 0.02897873147160968, 'max_depth': 8, 'n_estimators': 101, 'subsample': 0.5789094314361494, 'colsample_bytree': 0.6613416681397621, 'gamma': 0.03941964177962659, 'reg_alpha': 0.013600864278787036, 'reg_lambda': 1.108999360518536}. Best is trial 3 with value: 0.9739856137835355.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:33] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:33] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:34] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:34,202] Trial 12 finished with value: 0.9717383020772159 and parameters: {'learning_rate': 0.08650881613671925, 'max_depth': 8, 'n_estimators': 153, 'subsample': 0.5027178193297076, 'colsample_bytree': 0.6630111635669316, 'gamma': 0.9668433186745844, 'reg_alpha': 0.2982195343119588, 'reg_lambda': 1.4849507513376095}. Best is trial 3 with value: 0.9739856137835355.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:34] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:34] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:35] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:35,488] Trial 13 finished with value: 0.974375863642389 and parameters: {'learning_rate': 0.02128999803621827, 'max_depth': 5, 'n_estimators': 452, 'subsample': 0.652474189818298, 'colsample_bytree': 0.5954325603380553, 'gamma': 1.0227920107854167, 'reg_alpha': 0.3045253135480303, 'reg_lambda': 0.5475405122463529}. Best is trial 13 with value: 0.974375863642389.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:35] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:35] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:36] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:37,092] Trial 14 finished with value: 0.9710923757728326 and parameters: {'learning_rate': 0.01589467284226064, 'max_depth': 5, 'n_estimators': 490, 'subsample': 0.6476850175707015, 'colsample_bytree': 0.9015065089123261, 'gamma': 1.336603721751301, 'reg_alpha': 0.38074508145949804, 'reg_lambda': 0.5037213537255324}. Best is trial 13 with value: 0.974375863642389.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:37] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:37] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:38,578] Trial 15 finished with value: 0.9746777128846316 and parameters: {'learning_rate': 0.023786409926701193, 'max_depth': 5, 'n_estimators': 418, 'subsample': 0.7807311451928196, 'colsample_bytree': 0.5689875252076901, 'gamma': 0.9154193331323314, 'reg_alpha': 0.1567016603703031, 'reg_lambda': 0.5359045103073746}. Best is trial 15 with value: 0.9746777128846316.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:39,629] Trial 16 finished with value: 0.9724581096763792 and parameters: {'learning_rate': 0.022228084135719806, 'max_depth': 4, 'n_estimators': 420, 'subsample': 0.7051948532821349, 'colsample_bytree': 0.5776245238968375, 'gamma': 1.6642290019082107, 'reg_alpha': 0.16797429716070222, 'reg_lambda': 0.5190634023297074}. Best is trial 15 with value: 0.9746777128846316.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:40] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:40] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:41,084] Trial 17 finished with value: 0.9724751844099847 and parameters: {'learning_rate': 0.011210438163772297, 'max_depth': 5, 'n_estimators': 426, 'subsample': 0.7764578636280757, 'colsample_bytree': 0.5872877798880954, 'gamma': 0.8001019863847911, 'reg_alpha': 0.16161762451721182, 'reg_lambda': 0.6535989935209859}. Best is trial 15 with value: 0.9746777128846316.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:41] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:41] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:41] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:42,127] Trial 18 finished with value: 0.9721051172814835 and parameters: {'learning_rate': 0.027421154087609378, 'max_depth': 4, 'n_estimators': 431, 'subsample': 0.6375602394573753, 'colsample_bytree': 0.6997619995623363, 'gamma': 1.8295970789037002, 'reg_alpha': 0.46258987784346073, 'reg_lambda': 0.8957304403050065}. Best is trial 15 with value: 0.9746777128846316.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:42] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:42] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:42] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:43,145] Trial 19 finished with value: 0.9699527615835527 and parameters: {'learning_rate': 0.016605216430032516, 'max_depth': 6, 'n_estimators': 396, 'subsample': 0.9721572549114563, 'colsample_bytree': 0.5000658062890075, 'gamma': 3.3304691470930763, 'reg_alpha': 0.15909672178686576, 'reg_lambda': 0.6020279705447587}. Best is trial 15 with value: 0.9746777128846316.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:43] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:43] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:43] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:44,146] Trial 20 finished with value: 0.9737173768624846 and parameters: {'learning_rate': 0.04437485680986357, 'max_depth': 4, 'n_estimators': 459, 'subsample': 0.9019339716226056, 'colsample_bytree': 0.5747122142493636, 'gamma': 0.9152944409792876, 'reg_alpha': 0.27857326222550205, 'reg_lambda': 0.8030825027919167}. Best is trial 15 with value: 0.9746777128846316.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:44,943] Trial 21 finished with value: 0.9740090968161144 and parameters: {'learning_rate': 0.07083517253542959, 'max_depth': 6, 'n_estimators': 313, 'subsample': 0.8115925533081947, 'colsample_bytree': 0.7431677697331716, 'gamma': 0.6247170195587692, 'reg_alpha': 0.7621860366791884, 'reg_lambda': 1.0305711351491083}. Best is trial 15 with value: 0.9746777128846316.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:45,684] Trial 22 finished with value: 0.9729877254048859 and parameters: {'learning_rate': 0.12168348015829274, 'max_depth': 6, 'n_estimators': 327, 'subsample': 0.8311867899434586, 'colsample_bytree': 0.7149562752361043, 'gamma': 0.6488723258922213, 'reg_alpha': 0.7658358023210158, 'reg_lambda': 0.9686280047151048}. Best is trial 15 with value: 0.9746777128846316.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:46] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:46] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:46,718] Trial 23 finished with value: 0.9727397635131835 and parameters: {'learning_rate': 0.0276458274751429, 'max_depth': 5, 'n_estimators': 388, 'subsample': 0.753935522884318, 'colsample_bytree': 0.6061663017451786, 'gamma': 1.177148278307682, 'reg_alpha': 0.38789027486351274, 'reg_lambda': 0.6311340644007407}. Best is trial 15 with value: 0.9746777128846316.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:46] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:47] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:47] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:47,604] Trial 24 finished with value: 0.9711988827680571 and parameters: {'learning_rate': 0.01662650402154785, 'max_depth': 6, 'n_estimators': 257, 'subsample': 0.6936881076794913, 'colsample_bytree': 0.7557050854240317, 'gamma': 2.002024262969683, 'reg_alpha': 0.4741212474698853, 'reg_lambda': 0.5003067130002012}. Best is trial 15 with value: 0.9746777128846316.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:47] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:47] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:48] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:48,833] Trial 25 finished with value: 0.9743669412109436 and parameters: {'learning_rate': 0.06165719015975169, 'max_depth': 4, 'n_estimators': 452, 'subsample': 0.8577291561636643, 'colsample_bytree': 0.5455422762909621, 'gamma': 0.4734741839730363, 'reg_alpha': 0.09893233866644893, 'reg_lambda': 1.2933617349553188}. Best is trial 15 with value: 0.9746777128846316.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:48] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:49] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:50,476] Trial 26 finished with value: 0.9727379247619901 and parameters: {'learning_rate': 0.03404100525353749, 'max_depth': 4, 'n_estimators': 488, 'subsample': 0.8643707198583092, 'colsample_bytree': 0.54385302645681, 'gamma': 1.2069990765532692, 'reg_alpha': 0.0976336960862091, 'reg_lambda': 1.473713830587881}. Best is trial 15 with value: 0.9746777128846316.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:51] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:51,680] Trial 27 finished with value: 0.9749978355138528 and parameters: {'learning_rate': 0.021584703745223574, 'max_depth': 3, 'n_estimators': 452, 'subsample': 0.934302826787354, 'colsample_bytree': 0.622250085539741, 'gamma': 0.4179734173595339, 'reg_alpha': 0.23503853593951496, 'reg_lambda': 1.3480404465335012}. Best is trial 27 with value: 0.9749978355138528.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:51] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:51] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:52] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:52,539] Trial 28 finished with value: 0.9679521801349306 and parameters: {'learning_rate': 0.0220555136119193, 'max_depth': 3, 'n_estimators': 403, 'subsample': 0.9337948515571047, 'colsample_bytree': 0.6156349489973644, 'gamma': 4.860934576072446, 'reg_alpha': 0.22709360064261055, 'reg_lambda': 1.6603235481255547}. Best is trial 27 with value: 0.9749978355138528.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:52] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:52] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:53] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:53,825] Trial 29 finished with value: 0.9724701663499746 and parameters: {'learning_rate': 0.012765648392758282, 'max_depth': 3, 'n_estimators': 499, 'subsample': 0.9384893735038857, 'colsample_bytree': 0.6825073334798041, 'gamma': 0.4269337489887617, 'reg_alpha': 0.39810115808096835, 'reg_lambda': 0.8567384879828717}. Best is trial 27 with value: 0.9749978355138528.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:53] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:54] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:54] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:54,870] Trial 30 finished with value: 0.9672358608553876 and parameters: {'learning_rate': 0.014035801505719321, 'max_depth': 5, 'n_estimators': 445, 'subsample': 0.581674488763864, 'colsample_bytree': 0.6310929991799473, 'gamma': 4.237666778990414, 'reg_alpha': 0.22970797410973026, 'reg_lambda': 1.5842831374285857}. Best is trial 27 with value: 0.9749978355138528.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:54] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:55] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:55] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:56,001] Trial 31 finished with value: 0.9753558819528729 and parameters: {'learning_rate': 0.04795764424021148, 'max_depth': 4, 'n_estimators': 462, 'subsample': 0.9312540370697474, 'colsample_bytree': 0.5452544695231513, 'gamma': 0.39021746892016335, 'reg_alpha': 0.08125959309034914, 'reg_lambda': 1.3369774891487336}. Best is trial 31 with value: 0.9753558819528729.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:56] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:56] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:56] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:57,409] Trial 32 finished with value: 0.9756862730254618 and parameters: {'learning_rate': 0.020225154270829306, 'max_depth': 4, 'n_estimators': 471, 'subsample': 0.9933323139113629, 'colsample_bytree': 0.557548682419377, 'gamma': 0.22835157642018147, 'reg_alpha': 0.08811907955991055, 'reg_lambda': 1.335184471519699}. Best is trial 32 with value: 0.9756862730254618.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:57] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:57] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:58] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:58,404] Trial 33 finished with value: 0.9750098387726371 and parameters: {'learning_rate': 0.043451811870885565, 'max_depth': 3, 'n_estimators': 378, 'subsample': 0.9998069881863152, 'colsample_bytree': 0.5346613025729927, 'gamma': 0.01874169593870123, 'reg_alpha': 0.07726672911435202, 'reg_lambda': 1.393267780076604}. Best is trial 32 with value: 0.9756862730254618.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:58] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:58] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:59] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:24:59,562] Trial 34 finished with value: 0.9759987887734439 and parameters: {'learning_rate': 0.04145683991276192, 'max_depth': 3, 'n_estimators': 472, 'subsample': 0.9960993922701864, 'colsample_bytree': 0.5291132383608846, 'gamma': 0.16597062458194747, 'reg_alpha': 0.07465008151914286, 'reg_lambda': 1.3505317121543292}. Best is trial 34 with value: 0.9759987887734439.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:59] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:24:59] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:00] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:25:00,635] Trial 35 finished with value: 0.9760018509856626 and parameters: {'learning_rate': 0.04338924774689018, 'max_depth': 3, 'n_estimators': 372, 'subsample': 0.9961637416014223, 'colsample_bytree': 0.5250307915911541, 'gamma': 0.089472373412986, 'reg_alpha': 0.07060702725294077, 'reg_lambda': 1.199075730870321}. Best is trial 35 with value: 0.9760018509856626.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:00] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:01] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:01] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:25:02,199] Trial 36 finished with value: 0.9756873874502064 and parameters: {'learning_rate': 0.04644763577488686, 'max_depth': 4, 'n_estimators': 476, 'subsample': 0.9971556214713242, 'colsample_bytree': 0.5196302876313708, 'gamma': 0.23483414759568025, 'reg_alpha': 0.015847173499432612, 'reg_lambda': 1.1924182940765298}. Best is trial 35 with value: 0.9760018509856626.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:02] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:02] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:03] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:25:03,533] Trial 37 finished with value: 0.9760056360865592 and parameters: {'learning_rate': 0.035750445192011045, 'max_depth': 3, 'n_estimators': 479, 'subsample': 0.9923960031663909, 'colsample_bytree': 0.5059730270131048, 'gamma': 0.20882369854081836, 'reg_alpha': 0.010193088277070203, 'reg_lambda': 1.1976673629432582}. Best is trial 37 with value: 0.9760056360865592.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:03] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:03] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:04] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:25:04,480] Trial 38 finished with value: 0.9747324685663862 and parameters: {'learning_rate': 0.03672030932270479, 'max_depth': 3, 'n_estimators': 351, 'subsample': 0.9687501372663595, 'colsample_bytree': 0.5096384413332946, 'gamma': 0.17340660484978734, 'reg_alpha': 0.01372808182403423, 'reg_lambda': 1.203612205826589}. Best is trial 37 with value: 0.9760056360865592.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:04] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:04] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:05] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:25:05,709] Trial 39 finished with value: 0.9750565187082961 and parameters: {'learning_rate': 0.08202898584988622, 'max_depth': 3, 'n_estimators': 481, 'subsample': 0.9594653561350804, 'colsample_bytree': 0.5244044753305722, 'gamma': 0.004028428063166806, 'reg_alpha': 0.00238330056877587, 'reg_lambda': 1.2116385344482048}. Best is trial 37 with value: 0.9760056360865592.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:05] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:06] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:06] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:25:06,577] Trial 40 finished with value: 0.9724208974004469 and parameters: {'learning_rate': 0.05532941087346497, 'max_depth': 3, 'n_estimators': 410, 'subsample': 0.9102122006875693, 'colsample_bytree': 0.5014502689495242, 'gamma': 0.7271866195801995, 'reg_alpha': 0.8564051758242506, 'reg_lambda': 1.1357913905598744}. Best is trial 37 with value: 0.9760056360865592.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:06] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:07] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:07] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:25:07,788] Trial 41 finished with value: 0.9750584075016419 and parameters: {'learning_rate': 0.03178569268192699, 'max_depth': 4, 'n_estimators': 479, 'subsample': 0.9998474294687011, 'colsample_bytree': 0.558082207121432, 'gamma': 0.2547601070989837, 'reg_alpha': 0.05502342144712948, 'reg_lambda': 1.487996446090298}. Best is trial 37 with value: 0.9760056360865592.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:07] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:08] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:08] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:25:08,769] Trial 42 finished with value: 0.9724460823187416 and parameters: {'learning_rate': 0.04041305739288749, 'max_depth': 3, 'n_estimators': 436, 'subsample': 0.978584149677985, 'colsample_bytree': 0.5308336641637503, 'gamma': 0.5500280978778321, 'reg_alpha': 0.12291927338762308, 'reg_lambda': 1.238365424047223}. Best is trial 37 with value: 0.9760056360865592.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:08] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:09] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:09] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:25:09,899] Trial 43 finished with value: 0.9753570770226477 and parameters: {'learning_rate': 0.05046392342757151, 'max_depth': 4, 'n_estimators': 500, 'subsample': 0.998758417908461, 'colsample_bytree': 0.5619218787862778, 'gamma': 0.22815577892210584, 'reg_alpha': 0.03939696225973303, 'reg_lambda': 1.06847578032127}. Best is trial 37 with value: 0.9760056360865592.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:09] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:10] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:10] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:25:10,512] Trial 44 finished with value: 0.9699902396247269 and parameters: {'learning_rate': 0.19968097508611016, 'max_depth': 3, 'n_estimators': 334, 'subsample': 0.9580187900524776, 'colsample_bytree': 0.5267799893302467, 'gamma': 3.136471154972924, 'reg_alpha': 0.11339763579033516, 'reg_lambda': 1.2034461511132706}. Best is trial 37 with value: 0.9760056360865592.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:10] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:10] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:25:11,482] Trial 45 finished with value: 0.9753238265341307 and parameters: {'learning_rate': 0.07149485682169657, 'max_depth': 4, 'n_estimators': 369, 'subsample': 0.9089355151048484, 'colsample_bytree': 0.5903952680572807, 'gamma': 0.25472331779559293, 'reg_alpha': 0.201834192869906, 'reg_lambda': 1.2854962644967982}. Best is trial 37 with value: 0.9760056360865592.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:12] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:25:12,569] Trial 46 finished with value: 0.9724524429710316 and parameters: {'learning_rate': 0.031626934861506424, 'max_depth': 3, 'n_estimators': 471, 'subsample': 0.9782206060348834, 'colsample_bytree': 0.8899193381344855, 'gamma': 1.4097369217218256, 'reg_alpha': 0.04934160849686682, 'reg_lambda': 1.4211547123346682}. Best is trial 37 with value: 0.9760056360865592.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:12] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:13] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:13] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:25:14,227] Trial 47 finished with value: 0.9714792982325603 and parameters: {'learning_rate': 0.03835625996490321, 'max_depth': 4, 'n_estimators': 472, 'subsample': 0.9520890626379014, 'colsample_bytree': 0.5172423445147409, 'gamma': 0.7194221675576543, 'reg_alpha': 0.9771571202270859, 'reg_lambda': 1.9112394126546652}. Best is trial 37 with value: 0.9760056360865592.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:14] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:14] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:14] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:25:15,274] Trial 48 finished with value: 0.9746505375571003 and parameters: {'learning_rate': 0.06097382136719203, 'max_depth': 3, 'n_estimators': 442, 'subsample': 0.8816479844907333, 'colsample_bytree': 0.9589056299080658, 'gamma': 1.1000199487187396, 'reg_alpha': 0.1311848075880351, 'reg_lambda': 1.5708159762941443}. Best is trial 37 with value: 0.9760056360865592.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:15] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:15] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:15] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:25:16,314] Trial 49 finished with value: 0.9727838275196095 and parameters: {'learning_rate': 0.047374040972755924, 'max_depth': 10, 'n_estimators': 247, 'subsample': 0.9851686514191835, 'colsample_bytree': 0.5544340207830762, 'gamma': 0.20929817927339164, 'reg_alpha': 0.004299042717641162, 'reg_lambda': 1.1545261502832105}. Best is trial 37 with value: 0.9760056360865592.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: \n",
            "{'learning_rate': 0.035750445192011045, 'max_depth': 3, 'n_estimators': 479, 'subsample': 0.9923960031663909, 'colsample_bytree': 0.5059730270131048, 'gamma': 0.20882369854081836, 'reg_alpha': 0.010193088277070203, 'reg_lambda': 1.1976673629432582}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "3D1X9dfN4w5g",
        "outputId": "de0d22a2-952f-4a9b-fc0d-c10dd8dfaf59"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:25:22] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, device='cuda', early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric='logloss',\n",
              "              feature_types=None, feature_weights=None, gamma=0.1,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
              "              num_parallel_tree=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"‚ñ∏\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"‚ñæ\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, feature_weights=None, gamma=0.1,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
              "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, feature_weights=None, gamma=0.1,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
              "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb.fit(X_train, y_train)\n",
        "y_pred=xgb.predict(X_test)\n",
        "y_proba = xgb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "accuracy=accuracy_score(y_test, y_pred)\n",
        "f1=f1_score(y_test, y_pred)\n",
        "roc_auc=roc_auc_score(y_test, y_proba)\n",
        "\n",
        "print(f\"Accuracy; {accuracy: .4f}\")\n",
        "print(f\"F1-score; {f1: .4f}\")\n",
        "print(f\"ROC-AUC; {roc_auc: .4f}\")\n",
        "print(\"\\nClassification Report: \\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C-rdWEK5UiD",
        "outputId": "8bb3ea3f-b424-4206-cffa-a474040324d9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:26:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy;  0.9636\n",
            "F1-score;  0.9792\n",
            "ROC-AUC;  0.9763\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.82      0.85        57\n",
            "           1       0.97      0.98      0.98       382\n",
            "\n",
            "    accuracy                           0.96       439\n",
            "   macro avg       0.93      0.90      0.92       439\n",
            "weighted avg       0.96      0.96      0.96       439\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm=confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d',cmap='Blues', xticklabels=['No churn', 'churn'], yticklabels=['No churn', 'churn'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "NLT8SsgQ6Id2",
        "outputId": "07bb4f61-04ed-41fa-bea6-5978d5c64dfe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(sampling_strategy=0.73, random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "ZlMeiVYc7WMb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    param={\n",
        "        'objective':'binary:logistic',\n",
        "        'eval_metric':'logloss',\n",
        "        'use_label_encoder':False,\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.5, 2),\n",
        "        'random_state': 42,\n",
        "        'use_label_encoder': False,\n",
        "        'device': \"cuda\"\n",
        "    }\n",
        "\n",
        "    model=XGBClassifier(**param)\n",
        "\n",
        "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    scores=cross_val_score(model, X_train_resampled, y_train_resampled, cv=cv, scoring='f1')\n",
        "    return scores.mean()\n",
        "\n",
        "study=optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"Best trial: \")\n",
        "trial=study.best_trial\n",
        "print(trial.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLae6-Iv7Zgr",
        "outputId": "4f6f9087-7639-4936-85d2-8b98cb04fa1e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-01-15 18:32:09,676] A new study created in memory with name: no-name-e6ee9538-e0e8-479d-b438-fa9ff8029eb4\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:09] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:10] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:11,655] Trial 0 finished with value: 0.9573513584232382 and parameters: {'learning_rate': 0.011870611934474636, 'max_depth': 5, 'n_estimators': 321, 'subsample': 0.7181042247533995, 'colsample_bytree': 0.5588462575180184, 'gamma': 3.2602701470509183, 'reg_alpha': 0.810494190090297, 'reg_lambda': 1.9740992092186342}. Best is trial 0 with value: 0.9573513584232382.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:12] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:13] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:14,161] Trial 1 finished with value: 0.9685035711004627 and parameters: {'learning_rate': 0.017031955706149588, 'max_depth': 8, 'n_estimators': 387, 'subsample': 0.7774932240560045, 'colsample_bytree': 0.5457752745079925, 'gamma': 1.2885758018169473, 'reg_alpha': 0.6432464273033535, 'reg_lambda': 1.8280979165468845}. Best is trial 1 with value: 0.9685035711004627.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:14] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:14] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:15] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:15,720] Trial 2 finished with value: 0.9657254531321217 and parameters: {'learning_rate': 0.018755895071486825, 'max_depth': 6, 'n_estimators': 314, 'subsample': 0.6390151817565899, 'colsample_bytree': 0.9812384009690176, 'gamma': 3.107392248477062, 'reg_alpha': 0.31492045187338846, 'reg_lambda': 0.6272685077244744}. Best is trial 1 with value: 0.9685035711004627.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:15] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:16] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:16] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:16,633] Trial 3 finished with value: 0.9638712976156952 and parameters: {'learning_rate': 0.055213823068849546, 'max_depth': 8, 'n_estimators': 236, 'subsample': 0.7232221575037464, 'colsample_bytree': 0.7056073005270934, 'gamma': 3.8578892042852067, 'reg_alpha': 0.06590542290984647, 'reg_lambda': 0.8704342574600581}. Best is trial 1 with value: 0.9685035711004627.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:16] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:17,698] Trial 4 finished with value: 0.9671560262358593 and parameters: {'learning_rate': 0.25689782949624546, 'max_depth': 9, 'n_estimators': 500, 'subsample': 0.7755541298143862, 'colsample_bytree': 0.5209949964566161, 'gamma': 2.9929304062512294, 'reg_alpha': 0.20416355642365092, 'reg_lambda': 1.2838686259796388}. Best is trial 1 with value: 0.9685035711004627.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:18] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:18] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:19,195] Trial 5 finished with value: 0.9600613499301613 and parameters: {'learning_rate': 0.012744504769166342, 'max_depth': 6, 'n_estimators': 487, 'subsample': 0.5748756882823809, 'colsample_bytree': 0.8266336791660672, 'gamma': 4.54828276220057, 'reg_alpha': 0.005258540523268462, 'reg_lambda': 1.4413843883378263}. Best is trial 1 with value: 0.9685035711004627.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:19,884] Trial 6 finished with value: 0.9593077833132696 and parameters: {'learning_rate': 0.016293283073896755, 'max_depth': 5, 'n_estimators': 173, 'subsample': 0.8588732050794473, 'colsample_bytree': 0.71081756720628, 'gamma': 3.561391574093238, 'reg_alpha': 0.40464341261083325, 'reg_lambda': 0.9629041709771498}. Best is trial 1 with value: 0.9685035711004627.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:20] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:20] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:21,169] Trial 7 finished with value: 0.9674057111078055 and parameters: {'learning_rate': 0.036806636858512896, 'max_depth': 9, 'n_estimators': 493, 'subsample': 0.7878556318302452, 'colsample_bytree': 0.9927109437038741, 'gamma': 2.0057995541968268, 'reg_alpha': 0.8661010944006206, 'reg_lambda': 1.6904244197591447}. Best is trial 1 with value: 0.9685035711004627.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:21] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:21] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:22] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:22,479] Trial 8 finished with value: 0.9740829047567697 and parameters: {'learning_rate': 0.03581199869985884, 'max_depth': 5, 'n_estimators': 379, 'subsample': 0.6722011367983725, 'colsample_bytree': 0.7098822769380893, 'gamma': 0.5275702207634075, 'reg_alpha': 0.1503661692360051, 'reg_lambda': 0.8093329110799916}. Best is trial 8 with value: 0.9740829047567697.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:22] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:22] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:22] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:22,978] Trial 9 finished with value: 0.9617176647622738 and parameters: {'learning_rate': 0.13788230638297574, 'max_depth': 10, 'n_estimators': 212, 'subsample': 0.6036404640847137, 'colsample_bytree': 0.815943994789775, 'gamma': 4.927909093970041, 'reg_alpha': 0.7669218365902908, 'reg_lambda': 0.5260051766815865}. Best is trial 8 with value: 0.9740829047567697.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:23] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:23] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:23] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:23,400] Trial 10 finished with value: 0.9658015134595037 and parameters: {'learning_rate': 0.05565734017445682, 'max_depth': 4, 'n_estimators': 102, 'subsample': 0.5181371481559086, 'colsample_bytree': 0.6640510594486583, 'gamma': 0.039880493633018765, 'reg_alpha': 0.5420268326864184, 'reg_lambda': 0.9667682196294339}. Best is trial 8 with value: 0.9740829047567697.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:23] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:23] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:24] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:24,465] Trial 11 finished with value: 0.9678017063747414 and parameters: {'learning_rate': 0.030088110057691315, 'max_depth': 3, 'n_estimators': 394, 'subsample': 0.9097473653040212, 'colsample_bytree': 0.6012127769792281, 'gamma': 1.0219415603104092, 'reg_alpha': 0.5795961740468332, 'reg_lambda': 1.6811029475201267}. Best is trial 8 with value: 0.9740829047567697.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:24] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:24] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:25] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:25,712] Trial 12 finished with value: 0.9687751050109009 and parameters: {'learning_rate': 0.02948033495252905, 'max_depth': 7, 'n_estimators': 378, 'subsample': 0.674634633199135, 'colsample_bytree': 0.8051840035396729, 'gamma': 1.4471891101334375, 'reg_alpha': 0.6681540924313394, 'reg_lambda': 1.9306793039826242}. Best is trial 8 with value: 0.9740829047567697.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:25] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:26] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:26] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:27,530] Trial 13 finished with value: 0.975972387322816 and parameters: {'learning_rate': 0.07849631215556761, 'max_depth': 7, 'n_estimators': 405, 'subsample': 0.6742362543985541, 'colsample_bytree': 0.8078649531708633, 'gamma': 0.017490841259267143, 'reg_alpha': 0.2006927309820727, 'reg_lambda': 1.1915742886120821}. Best is trial 13 with value: 0.975972387322816.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:27] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:28] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:28] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:29,101] Trial 14 finished with value: 0.9730815600020549 and parameters: {'learning_rate': 0.08279904496502868, 'max_depth': 7, 'n_estimators': 433, 'subsample': 0.9994380831931613, 'colsample_bytree': 0.8991839847404265, 'gamma': 0.30605865804458227, 'reg_alpha': 0.18154859422293626, 'reg_lambda': 1.1904747144390257}. Best is trial 13 with value: 0.975972387322816.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:29] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:29] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:29] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:30,011] Trial 15 finished with value: 0.9727522841747227 and parameters: {'learning_rate': 0.10415453459564078, 'max_depth': 5, 'n_estimators': 346, 'subsample': 0.5079001942783047, 'colsample_bytree': 0.7615555642547964, 'gamma': 0.9511123339647923, 'reg_alpha': 0.38551045467546924, 'reg_lambda': 0.7740541169125552}. Best is trial 13 with value: 0.975972387322816.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:30,714] Trial 16 finished with value: 0.9737177058131965 and parameters: {'learning_rate': 0.15700380699501976, 'max_depth': 3, 'n_estimators': 264, 'subsample': 0.6672581467307616, 'colsample_bytree': 0.8797109109735413, 'gamma': 0.47881480135851134, 'reg_alpha': 0.999691406469335, 'reg_lambda': 1.1514045492600289}. Best is trial 13 with value: 0.975972387322816.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:31,747] Trial 17 finished with value: 0.9677983387302599 and parameters: {'learning_rate': 0.04251180720623705, 'max_depth': 4, 'n_estimators': 444, 'subsample': 0.8401727870230917, 'colsample_bytree': 0.629349109774803, 'gamma': 2.2690311091984112, 'reg_alpha': 0.16199228669011115, 'reg_lambda': 0.695835820590998}. Best is trial 13 with value: 0.975972387322816.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:32] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:32] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:32,771] Trial 18 finished with value: 0.9704167774604877 and parameters: {'learning_rate': 0.07123299796277366, 'max_depth': 6, 'n_estimators': 431, 'subsample': 0.5698820365955405, 'colsample_bytree': 0.7510724876182514, 'gamma': 1.7393287171128464, 'reg_alpha': 0.28572859637133974, 'reg_lambda': 1.434705420342058}. Best is trial 13 with value: 0.975972387322816.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:32] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:33] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:33] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:35,087] Trial 19 finished with value: 0.9720730186088059 and parameters: {'learning_rate': 0.024024084388543948, 'max_depth': 8, 'n_estimators': 337, 'subsample': 0.6933364137584253, 'colsample_bytree': 0.8991987143295151, 'gamma': 0.6097091159121826, 'reg_alpha': 0.4367576801719597, 'reg_lambda': 1.0790357836020383}. Best is trial 13 with value: 0.975972387322816.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:35] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:36] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:36] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:37,623] Trial 20 finished with value: 0.9671966789939225 and parameters: {'learning_rate': 0.22676270401845097, 'max_depth': 4, 'n_estimators': 274, 'subsample': 0.627549751442623, 'colsample_bytree': 0.685211210955014, 'gamma': 2.5315900886398723, 'reg_alpha': 0.08749044118297528, 'reg_lambda': 1.3396877763144623}. Best is trial 13 with value: 0.975972387322816.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:37] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:40] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:41,872] Trial 21 finished with value: 0.9737284039316255 and parameters: {'learning_rate': 0.16589214010152362, 'max_depth': 3, 'n_estimators': 284, 'subsample': 0.6629095426795252, 'colsample_bytree': 0.8853974610324467, 'gamma': 0.3757007055035324, 'reg_alpha': 0.9799199948433285, 'reg_lambda': 1.2035922888816832}. Best is trial 13 with value: 0.975972387322816.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:42] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:43] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:45,205] Trial 22 finished with value: 0.9733437639680252 and parameters: {'learning_rate': 0.15612323663771477, 'max_depth': 3, 'n_estimators': 363, 'subsample': 0.7406853850053907, 'colsample_bytree': 0.9447972417601954, 'gamma': 0.7597886404625039, 'reg_alpha': 0.2672425131444617, 'reg_lambda': 1.0491866428210002}. Best is trial 13 with value: 0.975972387322816.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:46] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:46] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:47,279] Trial 23 finished with value: 0.9726616414839069 and parameters: {'learning_rate': 0.1042486203086965, 'max_depth': 5, 'n_estimators': 278, 'subsample': 0.64578928279505, 'colsample_bytree': 0.8463946025822232, 'gamma': 0.2615796797670331, 'reg_alpha': 0.4686885442424809, 'reg_lambda': 1.5345546175503562}. Best is trial 13 with value: 0.975972387322816.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:47] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:47] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:48] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:48,738] Trial 24 finished with value: 0.9789532906605668 and parameters: {'learning_rate': 0.20180231923810266, 'max_depth': 7, 'n_estimators': 411, 'subsample': 0.591458040515333, 'colsample_bytree': 0.7839469780840844, 'gamma': 0.014372117259898842, 'reg_alpha': 0.14473341203307835, 'reg_lambda': 0.8036679836400707}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:48] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:49] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:49] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:50,448] Trial 25 finished with value: 0.9769556785787016 and parameters: {'learning_rate': 0.07255443544589447, 'max_depth': 7, 'n_estimators': 413, 'subsample': 0.555288392053473, 'colsample_bytree': 0.783182013694604, 'gamma': 0.021078889133531307, 'reg_alpha': 0.1125831600101721, 'reg_lambda': 0.8246462516311339}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:51] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:51] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:52,303] Trial 26 finished with value: 0.9762967704112784 and parameters: {'learning_rate': 0.07858666586447288, 'max_depth': 7, 'n_estimators': 454, 'subsample': 0.5520128800892181, 'colsample_bytree': 0.786147492285111, 'gamma': 0.06686587335676522, 'reg_alpha': 0.014030611198115273, 'reg_lambda': 0.575861332759122}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:52] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:52] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:53] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:53,791] Trial 27 finished with value: 0.9749822074606391 and parameters: {'learning_rate': 0.21302609143458529, 'max_depth': 7, 'n_estimators': 459, 'subsample': 0.5432656913594515, 'colsample_bytree': 0.7780365732955286, 'gamma': 1.2068627759712345, 'reg_alpha': 0.01095180954264205, 'reg_lambda': 0.5099086931660839}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:53] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:54] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:54] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:54,847] Trial 28 finished with value: 0.9726978890384892 and parameters: {'learning_rate': 0.11894893898991162, 'max_depth': 8, 'n_estimators': 465, 'subsample': 0.5989143085669251, 'colsample_bytree': 0.7756299975744363, 'gamma': 1.6449476686546758, 'reg_alpha': 0.057553805934148744, 'reg_lambda': 0.6209648934051086}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:54] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:55] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:55] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:56,359] Trial 29 finished with value: 0.9773151196119482 and parameters: {'learning_rate': 0.2877151959432421, 'max_depth': 9, 'n_estimators': 467, 'subsample': 0.5453906000522166, 'colsample_bytree': 0.8501991569152169, 'gamma': 0.003934729500253864, 'reg_alpha': 0.10046966123397495, 'reg_lambda': 0.8920254050022551}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:56] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:56] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:57] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:57,318] Trial 30 finished with value: 0.9743938608478525 and parameters: {'learning_rate': 0.27067096414470554, 'max_depth': 10, 'n_estimators': 427, 'subsample': 0.5314508842078748, 'colsample_bytree': 0.854816485446508, 'gamma': 0.8367420044427134, 'reg_alpha': 0.34565473707586325, 'reg_lambda': 0.9125125683550431}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:57] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:57] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:58] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:32:58,885] Trial 31 finished with value: 0.9753684936364153 and parameters: {'learning_rate': 0.20728847187598495, 'max_depth': 9, 'n_estimators': 471, 'subsample': 0.5476480128171136, 'colsample_bytree': 0.7277906756170699, 'gamma': 0.018225312376753046, 'reg_alpha': 0.10987030467150616, 'reg_lambda': 0.741902002950124}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:58] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:59] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:32:59] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:00,236] Trial 32 finished with value: 0.9769052171275076 and parameters: {'learning_rate': 0.07038791651751271, 'max_depth': 6, 'n_estimators': 411, 'subsample': 0.5790279406170996, 'colsample_bytree': 0.931894552899406, 'gamma': 0.32283452214123537, 'reg_alpha': 0.23773128758995482, 'reg_lambda': 0.632949552968625}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:00] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:00] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:00] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:01,146] Trial 33 finished with value: 0.9727363591385396 and parameters: {'learning_rate': 0.29991681540573845, 'max_depth': 6, 'n_estimators': 408, 'subsample': 0.6046316431328221, 'colsample_bytree': 0.9421826207253587, 'gamma': 0.674025731003096, 'reg_alpha': 0.2560634507802987, 'reg_lambda': 0.6716976130510337}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:01] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:01] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:01] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:02,286] Trial 34 finished with value: 0.9724105205438693 and parameters: {'learning_rate': 0.061102437563583197, 'max_depth': 8, 'n_estimators': 414, 'subsample': 0.5795848349391871, 'colsample_bytree': 0.941986780368551, 'gamma': 1.1995698387158553, 'reg_alpha': 0.23306360507760232, 'reg_lambda': 0.8009604836756001}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:02] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:02] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:03] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:03,565] Trial 35 finished with value: 0.9759372351822648 and parameters: {'learning_rate': 0.04596667298252538, 'max_depth': 6, 'n_estimators': 329, 'subsample': 0.5034068395330682, 'colsample_bytree': 0.8567077810664803, 'gamma': 0.41315645772198095, 'reg_alpha': 0.12247232091812492, 'reg_lambda': 0.8599728678643512}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:03] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:03] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:04] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:04,663] Trial 36 finished with value: 0.9686929344008991 and parameters: {'learning_rate': 0.1934487873439082, 'max_depth': 9, 'n_estimators': 362, 'subsample': 0.6313734541273257, 'colsample_bytree': 0.9746102724095843, 'gamma': 2.7596386734021716, 'reg_alpha': 0.3526830541996466, 'reg_lambda': 0.6925291231715435}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:04] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:05] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:05] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:06,384] Trial 37 finished with value: 0.9782751056170707 and parameters: {'learning_rate': 0.10201130367187465, 'max_depth': 6, 'n_estimators': 476, 'subsample': 0.5680314237857663, 'colsample_bytree': 0.8364904862228678, 'gamma': 0.2653539763427994, 'reg_alpha': 0.06926536096049263, 'reg_lambda': 1.0363027542986059}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:06] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:06] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:07] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:07,325] Trial 38 finished with value: 0.9635117181166942 and parameters: {'learning_rate': 0.12383526445492266, 'max_depth': 8, 'n_estimators': 477, 'subsample': 0.613677937032753, 'colsample_bytree': 0.7369841287495107, 'gamma': 3.9960756725180193, 'reg_alpha': 0.06323393710849871, 'reg_lambda': 1.0386169226130524}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:07] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:07] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:08] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:08,450] Trial 39 finished with value: 0.9727226988816667 and parameters: {'learning_rate': 0.10345499486082847, 'max_depth': 9, 'n_estimators': 493, 'subsample': 0.7143838111267289, 'colsample_bytree': 0.8354576535942645, 'gamma': 0.9823609917359541, 'reg_alpha': 0.13289375001116002, 'reg_lambda': 0.9481317160064024}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:08] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:08] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:09] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:09,426] Trial 40 finished with value: 0.9723904039207018 and parameters: {'learning_rate': 0.17387755958891632, 'max_depth': 10, 'n_estimators': 448, 'subsample': 0.5604658279751479, 'colsample_bytree': 0.8023115007626528, 'gamma': 1.4278901015798537, 'reg_alpha': 0.06278499716139802, 'reg_lambda': 0.8735988639562251}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:09] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:09] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:10] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:10,929] Trial 41 finished with value: 0.9746345812382261 and parameters: {'learning_rate': 0.06596121247704455, 'max_depth': 6, 'n_estimators': 418, 'subsample': 0.5839418557270031, 'colsample_bytree': 0.9197000073817556, 'gamma': 0.21672686224630774, 'reg_alpha': 0.22726626528552663, 'reg_lambda': 1.005004689717697}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:10] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:12,271] Trial 42 finished with value: 0.9720248522177437 and parameters: {'learning_rate': 0.09349776259444605, 'max_depth': 6, 'n_estimators': 500, 'subsample': 0.5286093408614667, 'colsample_bytree': 0.8716041379649558, 'gamma': 0.6038937484408304, 'reg_alpha': 0.1603586281103021, 'reg_lambda': 1.092370154288144}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:12] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:12] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:13] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:13,802] Trial 43 finished with value: 0.9745804422186685 and parameters: {'learning_rate': 0.047724872055748414, 'max_depth': 7, 'n_estimators': 391, 'subsample': 0.5797444523921654, 'colsample_bytree': 0.8324486006919423, 'gamma': 0.2754519317677683, 'reg_alpha': 0.30382940664106983, 'reg_lambda': 0.8027047579140985}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:13] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:14] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:14] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:15,042] Trial 44 finished with value: 0.9756275470516202 and parameters: {'learning_rate': 0.24652015752946274, 'max_depth': 6, 'n_estimators': 476, 'subsample': 0.5364382343109338, 'colsample_bytree': 0.907680222872215, 'gamma': 0.20504857609703922, 'reg_alpha': 0.0044148620163567825, 'reg_lambda': 0.6076629031282761}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:15] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:15] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:15] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:16,411] Trial 45 finished with value: 0.9743550302770693 and parameters: {'learning_rate': 0.12346641549333698, 'max_depth': 8, 'n_estimators': 440, 'subsample': 0.5963693700686131, 'colsample_bytree': 0.5033407921465887, 'gamma': 0.5075795205420465, 'reg_alpha': 0.09897672296456878, 'reg_lambda': 0.8753478986190835}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:16] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:16] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:17,848] Trial 46 finished with value: 0.9750241507016058 and parameters: {'learning_rate': 0.05457186918454472, 'max_depth': 7, 'n_estimators': 377, 'subsample': 0.6346082195593825, 'colsample_bytree': 0.7930187086878853, 'gamma': 0.7550100359709679, 'reg_alpha': 0.18932787233995396, 'reg_lambda': 0.7422486832065387}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:18] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:18] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:19,026] Trial 47 finished with value: 0.9653960294886313 and parameters: {'learning_rate': 0.010129037498810107, 'max_depth': 5, 'n_estimators': 301, 'subsample': 0.561207447427927, 'colsample_bytree': 0.9704933112511817, 'gamma': 1.081078902410598, 'reg_alpha': 0.13737445172947693, 'reg_lambda': 0.9896915224230787}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:19,650] Trial 48 finished with value: 0.9746567579485088 and parameters: {'learning_rate': 0.2996455390316044, 'max_depth': 6, 'n_estimators': 151, 'subsample': 0.5007116437091325, 'colsample_bytree': 0.8198662755266423, 'gamma': 0.09647957168076457, 'reg_alpha': 0.05625779257364469, 'reg_lambda': 0.9169079915803333}. Best is trial 24 with value: 0.9789532906605668.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:20] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:33:20] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-01-15 18:33:20,738] Trial 49 finished with value: 0.976618609310917 and parameters: {'learning_rate': 0.13993790383776042, 'max_depth': 7, 'n_estimators': 398, 'subsample': 0.6127161834713319, 'colsample_bytree': 0.7598551919257714, 'gamma': 0.40624529987287017, 'reg_alpha': 0.20981786959989315, 'reg_lambda': 0.8397514192475036}. Best is trial 24 with value: 0.9789532906605668.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: \n",
            "{'learning_rate': 0.20180231923810266, 'max_depth': 7, 'n_estimators': 411, 'subsample': 0.591458040515333, 'colsample_bytree': 0.7839469780840844, 'gamma': 0.014372117259898842, 'reg_alpha': 0.14473341203307835, 'reg_lambda': 0.8036679836400707}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Train XGBoost on resampled data\n",
        "xgb_smote = XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False,\n",
        "    learning_rate=0.09423988353764122,\n",
        "    max_depth=4,\n",
        "    n_estimators=227,\n",
        "    subsample=0.7510280011101731,\n",
        "    colsample_bytree= 0.7645977574980288,\n",
        "    gamma=1.3386893470230095,\n",
        "    reg_alpha=0.954715000010483,\n",
        "    reg_lambda=0.9214847598660335,\n",
        "    device=\"cuda\",\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "xgb_smote.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# 3. Predict on the original test set\n",
        "y_pred_smote = xgb_smote.predict(X_test)\n",
        "y_proba_smote = xgb_smote.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 4. Evaluate\n",
        "print(\"Accuracy; \", round(accuracy_score(y_test, y_pred_smote), 4))\n",
        "print(\"F1-score; \", round(f1_score(y_test, y_pred_smote), 4))\n",
        "print(\"ROC-AUC; \", round(roc_auc_score(y_test, y_proba_smote), 4))\n",
        "\n",
        "print(\"\\nClassification Report: \")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7A7_KgI7eaj",
        "outputId": "22292af6-7d6b-4610-9272-44cee1cbb727"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:40:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy;  0.9613\n",
            "F1-score;  0.9779\n",
            "ROC-AUC;  0.9722\n",
            "\n",
            "Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.82      0.85        57\n",
            "           1       0.97      0.98      0.98       382\n",
            "\n",
            "    accuracy                           0.96       439\n",
            "   macro avg       0.93      0.90      0.92       439\n",
            "weighted avg       0.96      0.96      0.96       439\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gy-UbGaB9asM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}